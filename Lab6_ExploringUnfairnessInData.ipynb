{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 6: Exploring Unfairness and Biased Data ⚖️"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "* Understanding and Applying Linear Regression \n",
    "* Gaining Awareness of Bias in Data and Unfairness in ML Algorithms\n",
    "* Data Exploration\n",
    "* Practice ML Workflow: Training, Testing, and Evaluation\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. [Unfairness](#1.-Unfairness)\n",
    "2. [Exploring Loan Approval Data](#2.-Exploring-Loan-Approval-Data)\n",
    "3. [Building a Model](#3.-Building-a-Model)\n",
    "4. [Towards a Fair Algorithm](#4.-Towards-a-Fair-Algorithm)\n",
    "5. [Becoming Data and Fairness Aware](#5.-Becoming-Data-and-Fairness-Aware)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Unfairness and Bias\n",
    "\n",
    "### An Example\n",
    "It is natural to assume that a model built from \"real-world\" data will inherently represent the world-at-large. We often take the data that we have for granted, especially when we are first getting started with Data Science. However, if we do not pay attention to what our data look like, how they were collected, and what features they contain, we may unknowingly create models that propagate cultural biases and unfairnesses.\n",
    "\n",
    "> _So, what does it mean for a model to be unfair?_\n",
    "\n",
    "Let's look at an example first. In 2014, Amazon began building programs that could automate the hiring process for engineers. They wanted a machine to be able to pick out the top resumes from the thousands they receive every year. This was reported in this [Reuters article](https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G) and has since been discussed by other sources.\n",
    "\n",
    "<img src=\"utility/images/undraw_hire_te5y.png\" alt=\"hire\" style=\"width: 600px;\"/>\n",
    "\n",
    "They trained their model on all of the resumes that they had, hoping that the model would be able to identify trends in keyword frequency within those applications. However, as they began to deploy their model, it became increasingly apparent that the model was discriminating against women. When engineers investigated why this was the case, they found that the data they trained the model with, the resumes, had mostly come from men. The model had learned to prefer resumes that didn't contain the word \"women's\" (as in “women’s chess club captain”) because that word wasn't frequently seen during its training. Although gender was not explicitly a feature of the dataset, it was still present in the dataset, encoded within the experiences that applicants reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources of Bias in Data\n",
    "\n",
    "Let's watch a short introductory [video](https://youtu.be/59bMh59JQDo) to learn about different types of bias. \n",
    "\n",
    "\n",
    "**Write-up!** Which type of bias(es) do think are reflected in the Amazon example? Discuss with your neighbors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon's case serves as a reminder that we must be careful of our data and models, even more so today as data becomes cheaper to collect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Scenario: Loan Approval\n",
    "\n",
    "Imagine that you are a data scientist at a bank and that one of your company's primary business areas is in lending money. The current loan approval process, that has been in place since the founding of the bank, has always relied on manual review of applications -- a process that is tedious and doesn't scale well in the modern age. The company wants to expand their business, but this archeic system is holding them back.\n",
    "\n",
    "Think about how to approach this problem, you immediately think of using the bank's past loan approval records to build a model that can learn how a human application reviewer decides which applications to approve and which to reject.\n",
    "\n",
    "<img src=\"utility/images/undraw_accept_request_vdsd.png\" alt=\"approval\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Defining Fairness\n",
    "It turns out that defining unfairness is a challenging task and in fact by adhering to one definition of fairness you might violate another. But that doesn't mean we shouldn't try. Below are five definitions applied to our load approval scenario (taken from [here](https://towardsdatascience.com/bias-and-algorithmic-fairness-10f0805edc2b)).\n",
    "\n",
    "> **Question:** Which one is *best*? Take a couple of minutes to read through and understand the different definitions. Then, discuss your choice(es) in your group!\n",
    "\n",
    "#### <a name=\"GUS\"></a>  Group Unaware Selection (also *Fairness though Blindness*)\n",
    "We simply disregard the gender information in the application process. Because there is a limited number of possible approvals a lender can grant they go to the most qualified individual based on objective, gender neutral criteria. But removing gender and gender-proxy information does not address historic biases and is generally not a very efficient process to mitigate bias as we will see in the worked example on loan application data below.\n",
    "\n",
    "#### Adjusted Group Thresholds \n",
    "Because historic biases make women appear less loan-worthy than men, e.g. work history and childcare responsibilities, we use different approval thresholds by group.\n",
    "\n",
    "#### Demographic Parity\n",
    "The approval rates should reflect the percentage of applications by group. But this would not take the risk of a default on a mortgage into account.\n",
    "\n",
    "#### Equal Opportunity \n",
    "The same percentage of men and women who are loan-worthy are given mortgages. This seems to meet the business objective of a mortgage lender and seems to be fair. _\"Individuals who qualify for a desirable outcome should have an equal chance of being correctly classified for this outcome.\"_ (Moritz Hardt)\n",
    "\n",
    "#### Precision Parity\n",
    "Not granting loans can have a very negative impact on an individual. In equal opportunity both groups have true positive parity. But if the model is wrong twice as often about women not paying back their loans (false negative) than the model would reject twice as many loan-worthy women than men. As such the model should be tuned so that the percentage of times the model is wrong in the total of approvals and denials is the same for both groups.\n",
    "\n",
    "**Discussion!** Consider the following questions: \n",
    "- Which definition would you use?\n",
    "- Does this choice violate other defintions/aspects of fairness?\n",
    "- Is there a universal definition for “fairness”?\n",
    "- What should we do when business requirements conflict with ethical requirements?\n",
    "- If we can’t reconcile these requirements, should we just stop?\n",
    "\n",
    "Discuss your choice(es) in your group or with your partner! This should take about 10min. \n",
    "\n",
    "**Write-up!** Record the discussion outcome and main thoughts (pros and cons)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring Loan Approval Data\n",
    "\n",
    "Now, it's time to look at our data. As you work through this section, try to look for hints of bias in the data set.\n",
    "\n",
    "\n",
    "### Acquiring the Data\n",
    "Before we begin, let's make sure that we have the data. The cell below checks if you have the `loan-payments.csv` file in the `utility/data` directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "\n",
    "\n",
    "data_dir = 'utility/data'\n",
    "\n",
    "assert exists(f'{data_dir}/loan-payments.csv'), 'Loan data file is missing.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's load our data. In the cell below, we read our [CSV][1] file into a [Pandas][2] [`DataFrame`][3] called `data`.\n",
    "\n",
    "\n",
    "\n",
    "[1]: https://en.wikipedia.org/wiki/Comma-separated_values\n",
    "[2]: https://pandas.pydata.org/\n",
    "[3]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(f'{data_dir}/loan-payments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** How many examples are in our data set? How many features does it have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, come up with a description of what you think each feature is and what type of feature each one is. Which one should be our target variable? Which ones do you think will be useful for our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Some Adjustments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's drop the columns in `data` that contain features that we are not interested in. Since `ID`s are not informative for predicting new loans, we can ignore them. Additionally, from our communications with the client lender, we know that `Effective Date`, `Due Date`, and `Date Closed` have all been factored into the `Risk Score`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** In the following cell, create a list containing the names of the features that you would like to **exclude** from the data set and store it in `not_interested`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "\n",
    "data = data.drop(not_interested, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see our new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Data Set\n",
    "\n",
    "Now that we have narrowed down the features we want to use, let's visualize them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** For each feature, make a new cell below and create a plot that we can use to understand the values of that feature. These plots should be appropriate for the type of each feature (e.g. use a bar plot for categorical features). Ensure that you have all the components off a nice plot, making sure to include things like axes labels, a legend, and a title. Also include a `raw` cell below each, describing what you see. _**Hint!** you can copy and paste groups of cells by shift-clicking them on the left._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utility.util import configure_plots\n",
    "\n",
    "# this cell is free!\n",
    "configure_plots()\n",
    "\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gender and Education\n",
    "\n",
    "Let's take a deeper look at the `Gender` and `Education` features.\n",
    "\n",
    "**Try this!** In the following cell, use `education_by_gender` to create a barplot that shows bars for each gender side-by-side for each education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender and education and count the number of examples\n",
    "# for each pair of feature values\n",
    "education_by_gender = data[['Gender', 'Education', 'Status']] \\\n",
    "    .groupby(['Gender', 'Education'], as_index=False) \\\n",
    "    .aggregate('count')\n",
    "\n",
    "# after aggregation, all columns other than the ones used to group will have\n",
    "# the same values. here we included `Status` as a placeholder column which\n",
    "# now holds counts, so should be renamed.\n",
    "education_by_gender = education_by_gender.rename({'Status': 'counts'}, axis=1)\n",
    "\n",
    "\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** In the following cell, use `loan_status_by_gender` to create a barplot that shows bars for each gender side-by-side for each education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by gender and education and count the number of examples\n",
    "# for each pair of feature values\n",
    "loan_status_by_gender = data[['Gender', 'Education', 'Status']] \\\n",
    "    .groupby(['Gender', 'Status'], as_index=False) \\\n",
    "    .aggregate('count')\n",
    "\n",
    "# after aggregation, all columns other than the ones used to group will have\n",
    "# the same values. here we included `Education` as a placeholder column which\n",
    "# now holds counts, so should be renamed.\n",
    "loan_status_by_gender = loan_status_by_gender.rename({'Education': 'counts'}, axis=1)\n",
    "\n",
    "\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** Is our data set biased? What do you think may have caused this? Think about the different types of bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a Model\n",
    "\n",
    "Now that we have a sense for the bias of our dataset, what can we try to mitigate the problem? Let's start building some models.\n",
    "\n",
    "<img src=\"utility/images/undraw_predictive_analytics_kf9n.png\" alt=\"analytics\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Categorical and Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, we will need to encode our categorical and [ordinal](https://stats.idre.ucla.edu/other/mult-pkg/whatstat/what-is-the-difference-between-categorical-ordinal-and-numerical-variables/) features with enumerations instead of the string values that they currently have. As a reminder, this is what our dataset looks like right now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** In the following cell, create a list containing the feature names of the categorical variables and store it in `categorical`. Repeat this for the ordinal variables, storing it in `ordinal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Variables\n",
    "\n",
    "An easy way to encode categorical variables is to use the [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) from `sklearn`. In the cell below, we create a list called `categorical` containing the names of the columns corresponding to the categorical features in our dataset. We then create and instance of a `LabelEncoder` and use it to transform the categorical features. We use `fit_transform` to remember the encodings it used so that we can apply the same transformation to other data sets (for example a test set if we had already split our data set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# make a copy of our data\n",
    "label_encoded = data[categorical].copy()\n",
    "\n",
    "# create a LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# fit the encoder and transform each categorical variable\n",
    "label_encoded = data[categorical].apply(label_encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding Ordinal Variables\n",
    "\n",
    "Likewise with the categorical variables, we can use an [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) to perform our encodings. However, in this case, the order of the labels is determined by the context of the problem. We need to give this order to the encoder.\n",
    "\n",
    "Note that the procedure for using the OrdinalEncoder is slightly different from the LabelEncoder in this case because we only have a single ordinal variable. However, the take away is that you want to apply the transformation to each observation for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# make a copy of the ordinal features\n",
    "ordinal_encoded = data[ordinal].copy()\n",
    "\n",
    "# create a LabelEncoder\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# fit the encoder and transform each categorical variable\n",
    "ordinal_encoded[ordinal] = ordinal_encoder.fit_transform(data[ordinal])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining the Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine the encoded features with the numerical data to form a new data set, `encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame with the continuous and encoded categorical features\n",
    "encoded = pd.concat([\n",
    "    \n",
    "    # selects the columns that are not in categorical using a set difference\n",
    "    data[data.columns.difference(categorical + ordinal)],\n",
    "    ordinal_encoded,\n",
    "    label_encoded\n",
    "    \n",
    "], axis=1) # concatenate the two data frames along the column axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the categorical values like \"PAIDOFF\" have now been replaced with numbers. We can see which numbers map to each value like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical + ordinal:\n",
    "    print(f'{column.title()}:')\n",
    "    \n",
    "    for value, encoding in sorted(zip(data[column].unique(), encoded[column].unique()),\n",
    "                                  key=lambda x: x[1]):\n",
    "        print(f'  {encoding}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's separate our features from our target variable, `Status`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Status'\n",
    "X, y = encoded.loc[:, encoded.columns != target], encoded[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing a Baseline\n",
    "\n",
    "Now we're ready to start building models. First, let's create a train/test split of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** Create a train/test split of `X` and `y` using a `test_size` of 20%, a `random_state` of 3, and with stratification by `y`. Consider why we need to use `stratify` in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let's train and evaluate a Logistic Regression model.\n",
    "\n",
    "**Try this!** Create a `LogisticRegression` model with 'liblinear' as the `solver` and `multi_class` set to 'auto'. Then, train the model.\n",
    "\n",
    "> In this case, we have three target classes — you don't have to worry about how this works, but feel free to ask if you are curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** In the cell below, evaluate the model's performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** How does our model perform on the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking a Closer Look!\n",
    "\n",
    "Let's also try looking at the model's performance on test examples of different genders.\n",
    "\n",
    "**Try this!** In the following cell, create a mask (a boolean array) of `X_test` that has true values when the loan's applicant was a woman and false otherwise. Store this mask in `test_female_applicants`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "\n",
    "assert test_female_applicants.sum() == 18, 'There should be 18 true values in your mask'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's write a function that will automate our evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "def evaluate(model, X_test, y_test, female_idx):\n",
    "    '''\n",
    "    Evaluates a MODEL on X_TEST, male examples in X_TEST, and female examples in X_TEST\n",
    "    '''\n",
    "    \n",
    "    assert isinstance(X_test, (pd.DataFrame, np.ndarray)), \\\n",
    "        f'expected `X_test` to be a pd.DataFrame or an np.ndarray (got {type(X_test)})'\n",
    "\n",
    "    assert female_idx is not None, \\\n",
    "        'Female index array required'\n",
    "\n",
    "    score = model.score(X_test, y_test)\n",
    "    mscore = model.score(X_test[~female_idx],\n",
    "                         y_test[~female_idx])\n",
    "    fscore = model.score(X_test[female_idx],\n",
    "                         y_test[female_idx])\n",
    "\n",
    "    print(dedent(f'''\n",
    "    Test Set Performance -----\n",
    "                  score: {score:0.3f}\n",
    "                    men: {mscore:0.3f}\n",
    "                  women: {fscore:0.3f}\n",
    "\n",
    "    ''').strip())\n",
    "\n",
    "evaluate(model, X_test, y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** What do you notice about these scores? How do these compare with the initial score we saw for the entire test set? What does this imply about our model and your selected fairness criteria?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Towards a Fair Algorithm\n",
    "\n",
    "Identifying a suitable definition of fairness seems to be just a first step. Now, we need to select a suitable mitigation strategy for biases. Again, mitigating bias is a complex topic and there is, again, no universal approach or silver bullet. **But again, we have to give it a try!**\n",
    "\n",
    "### Idea 1: Pre-processing\n",
    "\n",
    "Let's look at some potential mitigation strategies that can be applied before the modeling step.\n",
    "\n",
    "#### Dropping Gender — Group Unaware Selection\n",
    "So our model is biased with respect to gender and gender is a feature of the model. Would it help to ignore the gender feature during training (cf. [*Group Unaware Selection*](#GUS))? Let's try it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try repeating our procedure from our baseline experiment, but this time using all of the features except `gender` for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try this!** In the following cell, create a list of all feature names excluding \"Gender\" and store it in `not_gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here \n",
    "\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "model.fit(X_train[not_gender], y_train)\n",
    "\n",
    "evaluate(model, X_test[not_gender], y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, discuss the results and what this might imply about our model and our data. Also, discuss why it may or may not be a good idea to ignore \"protected variables\" like \"gender\" when training a model. Consider how other features may have contributed this this outcome. Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upsampling Minority\n",
    "\n",
    "Another idea is to artificially rebalance the data set by upsampling the minority. In the following cell, we compute the Male to Female ratio in our data set — the approximate number of times we need to repeat the female applicant examples to achieve an approximately equal proportion of examples from each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_train_male, N_train_female = X_train['Gender'].value_counts()\n",
    "number_of_repeats = int(N_train_male / N_train_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we perform the upsampling for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_male_idx = X_train['Gender'] == 1\n",
    "train_female_idx = X_train['Gender'] == 0\n",
    "\n",
    "X_train_upsampled = pd.concat([\n",
    "    X_train[train_male_idx],\n",
    "    pd.concat([X_train[train_female_idx]] * number_of_repeats, ignore_index=True)\n",
    "])\n",
    "\n",
    "y_train_upsampled = pd.concat([\n",
    "    y_train[train_male_idx],\n",
    "    pd.concat([y_train[train_female_idx]] * number_of_repeats, ignore_index=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's re-train the model and look at the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "model.fit(X_train_upsampled, y_train_upsampled)\n",
    "\n",
    "evaluate(model, X_test, y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this make a difference? What caveats can you come up for this strategy?\n",
    "\n",
    "**Write-up!** With your neighbor, discuss these results and speculate about why they have occured. Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 2: Changing the Model\n",
    "\n",
    "Next, let's consider some strategies related to model creation step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Separate Models\n",
    "\n",
    "What if we simply trained two different models, one for each gender? In the following cell, we create split our training set `X_train` into two separate data sets for each gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_male_idx = X_train['Gender'] == 1\n",
    "train_female_idx = X_train['Gender'] == 0\n",
    "\n",
    "X_train_male, y_train_male = X_train[train_male_idx], y_train[train_male_idx]\n",
    "X_train_female, y_train_female = X_train[train_female_idx], y_train[train_female_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's fit and evaluate a model trained on only male examples. We will evaluate it on the whole test set (both men and women)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "male_model.fit(X_train_male, y_train_male)\n",
    "\n",
    "evaluate(male_model, X_test, y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, discuss these results and speculate about why they have occured. Why did this model perform better for both men and women? Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "female_model.fit(X_train_female, y_train_female)\n",
    "\n",
    "evaluate(female_model, X_test, y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, discuss these results and speculate about why they have occured. Why did this model perform worse for both men and women? Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Features\n",
    "\n",
    "It's also plausible that a linear model is too simple to find a good fit for our data. In the following cell, we try to use a Polynomial model.\n",
    "\n",
    "> **For those who are interested**: a polynomial is a linear combination of non-linear terms. This means that we can use a linear model to fit polynomials simply by transforming our features into polynomial features before fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree)\n",
    "\n",
    "X_train_poly = poly.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "poly_model.fit(X_train_poly, y_train)\n",
    "\n",
    "evaluate(poly_model, poly.transform(X_test), y_test, test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, discuss these results. Briefly, what were some of the caveats we discussed about using more complex models? Is this 2nd degree polynomial (quadratic) model a good model? Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idea 3: Post-processing  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also some steps we can take after training a model. In the following example, we leverage the probabilitistic nature of Logistic regression to reason about the model's \"confidence\" in its predictions.\n",
    "\n",
    "Here, we set a threshold above which we will take the models predictions. Then, we will refer the cases that the model is not sure about for further, _possibly human_, evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# compute the class-label probabilities for each test example\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# find the examples that can be predicted with probability greater than threshold\n",
    "greater_than_threshold = np.any(probs > threshold, axis=1)\n",
    "\n",
    "# only make predictions for those examples whose labels can be predicted with enough confidence\n",
    "X_test_predictable = X_test[greater_than_threshold]\n",
    "y_hat = model.predict(X_test_predictable)\n",
    "\n",
    "print(f'Made predictions for {greater_than_threshold.mean():0.2%} of test applications.\\n')\n",
    "evaluate(model, X_test_predictable, y_test[greater_than_threshold], test_female_applicants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the cases that the model wasn't sure about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_not_predicted = X_test[~greater_than_threshold]\n",
    "y_test_not_predicted = y_test[~greater_than_threshold]\n",
    "\n",
    "not_predictable = data.iloc[X_test_not_predicted.index, :].copy()\n",
    "\n",
    "enc_status = {enc: val for enc, val in zip(encoded['Status'].unique(),\n",
    "                                           data['Status'].unique())}\n",
    "not_predictable['would-be prediction'] = list(map(lambda l: enc_status[l],\n",
    "                                                  model.predict(X_test_not_predicted)))\n",
    "\n",
    "not_predictable['p(would-be prediction)'] = probs[~greater_than_threshold].max(axis=1)\n",
    "not_predictable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write-up!** With your neighbor, discuss these results. Considering the problem and context, why might this be the best strategy out of the ones we have tried? Why not? Record your response below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your response here:** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that **all** of the above methods are **valid methods** to mitigate bias. For a specific application domain and dataset some will work while others don't. It is good to have all of them in your repertoire, when doing data science in the real-world!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Becoming Data and Fairness Aware\n",
    " \n",
    "<img src=\"utility/images/undraw_team_spirit_hrr4.png\" alt=\"team\" style=\"width: 600px;\"/>\n",
    "\n",
    "### Takeaways\n",
    "\n",
    "The goal of today's lab was to demonstrate how an accuracy score can mislead you into thinking that your model is great and that your mission has been accomplished. By digging only a little bit deeper and evaluating our model's performance on each gender separately, we found that it performed very differently between genders. It was biased!\n",
    "\n",
    "We ran into the same problem Amazon did with their resume reviewing algorithm. Because the data we used was imbalanced, we introduced bias into our model unintentionally.\n",
    "\n",
    "If you search online, you will find a myriad of ways that could be used to mitigate the effects of an imbalanced dataset. However, at the end of the day, the **best solution for both Amazon and us is to collect more complete data**.\n",
    "\n",
    "![takeaways](utility/images/takeaways.png)\n",
    "\n",
    "### What comes next? \n",
    "\n",
    "We have only barely scratched the surface of fairness in Data Science. The field is both complex and emerging. If you are looking for more information about, I recommend starting with [Google's overview](https://developers.google.com/machine-learning/fairness-overview/) of the topic.\n",
    "\n",
    "I hope that you will leave here today with a different, more careful perspective on your data and how it might unintentionally create bias in your models.\n",
    "\n",
    "I will also leave you with this quote from [a report](https://www.nap.edu/read/25104/chapter/13) by the [National Academies of Science, Engineering, and Medicine](https://www.nationalacademies.org).\n",
    "\n",
    "> ## The Data Science Oath\n",
    ">\n",
    "> I swear to fulfill, to the best of my ability and judgment, this covenant:\n",
    "> \n",
    "> \n",
    "> I will respect the hard-won scientific gains of those data scientists in whose steps I walk and gladly share such knowledge as is mine with those who follow.\n",
    "> \n",
    "> I will apply, for the benefit of society, all measures which are required, avoiding misrepresentations of data and analysis results.\n",
    ">\n",
    "> I will remember that there is art to data science as well as science and that consistency, candor, and compassion should outweigh the algorithm’s precision or the interventionist’s influence.\n",
    "> \n",
    "> I will not be ashamed to say, “I know not,” nor will I fail to call in my colleagues when the skills of another are needed for solving a problem.\n",
    ">\n",
    "> I will respect the privacy of my data subjects, for their data are not disclosed to me that the world may know, so I will tread with care in matters of privacy and security. If it is given to me to do good with my analyses, all thanks. But it may also be within my power to do harm, and this responsibility must be faced with humbleness and awareness of my own limitations.\n",
    ">\n",
    "> I will remember that my data are not just numbers without meaning or context, but represent real people and situations, and that my work may lead to unintended societal consequences, such as inequality, poverty, and disparities due to algorithmic bias. My responsibility must consider potential consequences of my extraction of meaning from data and ensure my analyses help make better decisions.\n",
    ">\n",
    "> I will perform personalization where appropriate, but I will always look for a path to fair treatment and nondiscrimination.\n",
    ">\n",
    "> I will remember that I remain a member of society, with special obligations to all my fellow human beings, those who need help and those who don’t.\n",
    ">\n",
    "> If I do not violate this oath, may I enjoy vitality and virtuosity, respected for my contributions and remembered for my leadership thereafter. May I always act to preserve the finest traditions of my calling and may I long experience the joy of helping those who can benefit from my work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
